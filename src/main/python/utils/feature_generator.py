"""
AIFX Feature Generator | AIFXç‰¹å¾µç”Ÿæˆå™¨

This module generates features for AI models by combining technical indicators,
market data preprocessing, and time-based feature engineering.
æ­¤æ¨¡çµ„é€šéŽçµåˆæŠ€è¡“æŒ‡æ¨™ã€å¸‚å ´æ•¸æ“šé è™•ç†å’ŒåŸºæ–¼æ™‚é–“çš„ç‰¹å¾µå·¥ç¨‹ç‚ºAIæ¨¡åž‹ç”Ÿæˆç‰¹å¾µã€‚

The FeatureGenerator bridges the gap between raw market data and AI model input.
FeatureGeneratoråœ¨åŽŸå§‹å¸‚å ´æ•¸æ“šå’ŒAIæ¨¡åž‹è¼¸å…¥ä¹‹é–“å»ºç«‹æ©‹æ¨‘ã€‚
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Union, Any
import warnings
warnings.filterwarnings('ignore')

from .logger import get_logger
from .data_preprocessor import DataPreprocessor
from .technical_indicators import TechnicalIndicators


class FeatureGenerator:
    """
    Feature generation class for AI models | AIæ¨¡åž‹ç‰¹å¾µç”Ÿæˆé¡ž
    
    Combines technical indicators, market data preprocessing, and time-based
    features to create comprehensive feature sets for AI model training and prediction.
    çµåˆæŠ€è¡“æŒ‡æ¨™ã€å¸‚å ´æ•¸æ“šé è™•ç†å’ŒåŸºæ–¼æ™‚é–“çš„ç‰¹å¾µï¼Œç‚ºAIæ¨¡åž‹è¨“ç·´å’Œé æ¸¬å‰µå»ºç¶œåˆç‰¹å¾µé›†ã€‚
    """
    
    def __init__(self, lookback_periods: List[int] = None):
        """
        Initialize feature generator | åˆå§‹åŒ–ç‰¹å¾µç”Ÿæˆå™¨
        
        Args:
            lookback_periods: List of periods for technical indicators | æŠ€è¡“æŒ‡æ¨™çš„é€±æœŸåˆ—è¡¨
        """
        self.logger = get_logger(__name__)
        self.data_preprocessor = DataPreprocessor()
        self.technical_indicators = TechnicalIndicators()
        
        # Default lookback periods for technical indicators | æŠ€è¡“æŒ‡æ¨™çš„é»˜èªå›žæœ›æœŸ
        self.lookback_periods = lookback_periods or [5, 10, 20, 50]
        
        # Feature names for tracking | ç”¨æ–¼è·Ÿè¹¤çš„ç‰¹å¾µåç¨±
        self.feature_names = []
        
        self.logger.info("âœ… FeatureGenerator initialized | ç‰¹å¾µç”Ÿæˆå™¨å·²åˆå§‹åŒ–")
    
    def generate_features(self, market_data: pd.DataFrame, symbol: str = "EURUSD") -> pd.DataFrame:
        """
        Generate comprehensive features from market data | å¾žå¸‚å ´æ•¸æ“šç”Ÿæˆç¶œåˆç‰¹å¾µ
        
        Args:
            market_data: OHLCV market data | OHLCVå¸‚å ´æ•¸æ“š
            symbol: Trading symbol | äº¤æ˜“å“ç¨®
            
        Returns:
            DataFrame with generated features | åŒ…å«ç”Ÿæˆç‰¹å¾µçš„æ•¸æ“šæ¡†
        """
        try:
            if market_data.empty:
                self.logger.warning("âš ï¸ Empty market data provided | æä¾›äº†ç©ºçš„å¸‚å ´æ•¸æ“š")
                return pd.DataFrame()
            
            # Ensure required columns exist | ç¢ºä¿æ‰€éœ€åˆ—å­˜åœ¨
            required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']
            if not all(col in market_data.columns for col in required_columns):
                self.logger.error(f"âŒ Missing required columns in market data | å¸‚å ´æ•¸æ“šä¸­ç¼ºå°‘å¿…éœ€åˆ—")
                return pd.DataFrame()
            
            self.logger.info(f"ðŸ”„ Generating features for {symbol} with {len(market_data)} data points")
            
            # Start with original market data | å¾žåŽŸå§‹å¸‚å ´æ•¸æ“šé–‹å§‹
            features_df = market_data.copy()
            
            # 1. Basic price features | åŸºæœ¬åƒ¹æ ¼ç‰¹å¾µ
            features_df = self._add_price_features(features_df)
            
            # 2. Technical indicators | æŠ€è¡“æŒ‡æ¨™
            features_df = self._add_technical_indicators(features_df)
            
            # 3. Time-based features | åŸºæ–¼æ™‚é–“çš„ç‰¹å¾µ
            features_df = self._add_time_features(features_df)
            
            # 4. Volatility features | æ³¢å‹•çŽ‡ç‰¹å¾µ
            features_df = self._add_volatility_features(features_df)
            
            # 5. Momentum features | å‹•é‡ç‰¹å¾µ
            features_df = self._add_momentum_features(features_df)
            
            # 6. Volume features | æˆäº¤é‡ç‰¹å¾µ
            features_df = self._add_volume_features(features_df)
            
            # 7. Statistical features | çµ±è¨ˆç‰¹å¾µ
            features_df = self._add_statistical_features(features_df)
            
            # Clean and validate features | æ¸…ç†å’Œé©—è­‰ç‰¹å¾µ
            features_df = self._clean_features(features_df)
            
            # Store feature names | å­˜å„²ç‰¹å¾µåç¨±
            self.feature_names = list(features_df.columns)
            
            self.logger.info(f"âœ… Generated {len(features_df.columns)} features for {symbol}")
            return features_df
            
        except Exception as e:
            self.logger.error(f"âŒ Error generating features: {str(e)}")
            return pd.DataFrame()
    
    def _add_price_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Add basic price-related features | æ·»åŠ åŸºæœ¬åƒ¹æ ¼ç›¸é—œç‰¹å¾µ"""
        try:
            # Price changes | åƒ¹æ ¼è®ŠåŒ–
            df['price_change'] = df['Close'] - df['Open']
            df['price_change_pct'] = (df['Close'] - df['Open']) / df['Open'] * 100
            
            # High-Low range | æœ€é«˜æœ€ä½Žåƒ¹ç¯„åœ
            df['hl_range'] = df['High'] - df['Low']
            df['hl_range_pct'] = (df['High'] - df['Low']) / df['Open'] * 100
            
            # Body and shadow ratios | å¯¦é«”å’Œå½±ç·šæ¯”çŽ‡
            df['body_size'] = abs(df['Close'] - df['Open'])
            df['upper_shadow'] = df['High'] - np.maximum(df['Open'], df['Close'])
            df['lower_shadow'] = np.minimum(df['Open'], df['Close']) - df['Low']
            
            # Typical price | å…¸åž‹åƒ¹æ ¼
            df['typical_price'] = (df['High'] + df['Low'] + df['Close']) / 3
            
            return df
        except Exception as e:
            self.logger.error(f"âŒ Error adding price features: {str(e)}")
            return df
    
    def _add_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """Add technical indicators | æ·»åŠ æŠ€è¡“æŒ‡æ¨™"""
        try:
            # Moving averages | ç§»å‹•å¹³å‡ç·š
            for period in self.lookback_periods:
                if len(df) >= period:
                    # Simple Moving Average
                    df[f'sma_{period}'] = self.technical_indicators.sma(df['Close'], period)
                    # Exponential Moving Average
                    df[f'ema_{period}'] = self.technical_indicators.ema(df['Close'], period)
                    
                    # Price relative to moving averages | åƒ¹æ ¼ç›¸å°æ–¼ç§»å‹•å¹³å‡ç·š
                    df[f'close_sma_{period}_ratio'] = df['Close'] / df[f'sma_{period}']
                    df[f'close_ema_{period}_ratio'] = df['Close'] / df[f'ema_{period}']
            
            # RSI | ç›¸å°å¼·å¼±æŒ‡æ•¸
            df['rsi_14'] = self.technical_indicators.rsi(df['Close'], 14)
            df['rsi_30'] = self.technical_indicators.rsi(df['Close'], 30)
            
            # MACD | æŒ‡æ•¸å¹³æ»‘ç§»å‹•å¹³å‡ç·š
            macd_result = self.technical_indicators.macd(df['Close'])
            df['macd'] = macd_result['macd']
            df['macd_signal'] = macd_result['signal']
            df['macd_histogram'] = macd_result['histogram']
            
            # Bollinger Bands | å¸ƒæž—å¸¶
            bb_result = self.technical_indicators.bollinger_bands(df['Close'])
            df['bb_upper'] = bb_result['upper']
            df['bb_middle'] = bb_result['middle']
            df['bb_lower'] = bb_result['lower']
            df['bb_width'] = bb_result['width']
            df['bb_position'] = (df['Close'] - bb_result['lower']) / (bb_result['upper'] - bb_result['lower'])
            
            # ATR | å¹³å‡çœŸå¯¦ç¯„åœ
            df['atr_14'] = self.technical_indicators.atr(df['High'], df['Low'], df['Close'], 14)
            
            return df
        except Exception as e:
            self.logger.error(f"âŒ Error adding technical indicators: {str(e)}")
            return df
    
    def _add_time_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Add time-based features | æ·»åŠ åŸºæ–¼æ™‚é–“çš„ç‰¹å¾µ"""
        try:
            if df.index.dtype != 'datetime64[ns]':
                # Try to convert index to datetime if it's not already | å¦‚æžœé‚„ä¸æ˜¯ï¼Œå˜—è©¦å°‡ç´¢å¼•è½‰æ›ç‚ºdatetime
                try:
                    df.index = pd.to_datetime(df.index)
                except:
                    self.logger.warning("âš ï¸ Could not convert index to datetime | ç„¡æ³•å°‡ç´¢å¼•è½‰æ›ç‚ºdatetime")
                    return df
            
            # Hour of day | ä¸€å¤©ä¸­çš„å°æ™‚
            df['hour'] = df.index.hour
            df['day_of_week'] = df.index.dayofweek
            df['day_of_month'] = df.index.day
            df['month'] = df.index.month
            
            # Trading session indicators | äº¤æ˜“æ™‚æ®µæŒ‡æ¨™
            # European session (7-16 GMT) | æ­æ´²æ™‚æ®µ
            df['european_session'] = ((df.index.hour >= 7) & (df.index.hour <= 16)).astype(int)
            # American session (13-22 GMT) | ç¾Žåœ‹æ™‚æ®µ
            df['american_session'] = ((df.index.hour >= 13) & (df.index.hour <= 22)).astype(int)
            # Asian session (21-6 GMT next day) | äºžæ´²æ™‚æ®µ
            df['asian_session'] = ((df.index.hour >= 21) | (df.index.hour <= 6)).astype(int)
            
            # Weekend indicator | é€±æœ«æŒ‡æ¨™
            df['is_weekend'] = (df.index.dayofweek >= 5).astype(int)
            
            return df
        except Exception as e:
            self.logger.error(f"âŒ Error adding time features: {str(e)}")
            return df
    
    def _add_volatility_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Add volatility features | æ·»åŠ æ³¢å‹•çŽ‡ç‰¹å¾µ"""
        try:
            # Price volatility over different periods | ä¸åŒé€±æœŸçš„åƒ¹æ ¼æ³¢å‹•çŽ‡
            for period in [5, 10, 20]:
                if len(df) >= period:
                    returns = df['Close'].pct_change()
                    df[f'volatility_{period}'] = returns.rolling(window=period).std() * np.sqrt(period)
            
            # Parkinson's volatility (using High and Low) | å¸•é‡‘æ£®æ³¢å‹•çŽ‡ï¼ˆä½¿ç”¨æœ€é«˜åƒ¹å’Œæœ€ä½Žåƒ¹ï¼‰
            df['parkinson_vol'] = np.sqrt(0.361 * np.log(df['High'] / df['Low']) ** 2)
            
            # Garman-Klass volatility | åŠ æ›¼-å…‹æ‹‰æ–¯æ³¢å‹•çŽ‡
            df['gk_volatility'] = 0.5 * np.log(df['High'] / df['Low']) ** 2 - (2 * np.log(2) - 1) * np.log(df['Close'] / df['Open']) ** 2
            
            return df
        except Exception as e:
            self.logger.error(f"âŒ Error adding volatility features: {str(e)}")
            return df
    
    def _add_momentum_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Add momentum features | æ·»åŠ å‹•é‡ç‰¹å¾µ"""
        try:
            # Rate of Change over different periods | ä¸åŒé€±æœŸçš„è®ŠåŒ–çŽ‡
            for period in [5, 10, 20]:
                if len(df) >= period:
                    df[f'roc_{period}'] = (df['Close'] - df['Close'].shift(period)) / df['Close'].shift(period) * 100
            
            # Williams %R | å¨å»‰æŒ‡æ¨™
            for period in [14, 30]:
                if len(df) >= period:
                    highest_high = df['High'].rolling(window=period).max()
                    lowest_low = df['Low'].rolling(window=period).min()
                    df[f'williams_r_{period}'] = (highest_high - df['Close']) / (highest_high - lowest_low) * -100
            
            # Commodity Channel Index | å•†å“é€šé“æŒ‡æ•¸
            df['cci'] = self.technical_indicators.cci(df['High'], df['Low'], df['Close'])
            
            return df
        except Exception as e:
            self.logger.error(f"âŒ Error adding momentum features: {str(e)}")
            return df
    
    def _add_volume_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Add volume-based features | æ·»åŠ åŸºæ–¼æˆäº¤é‡çš„ç‰¹å¾µ"""
        try:
            if 'Volume' not in df.columns or df['Volume'].sum() == 0:
                # For forex data, volume might not be meaningful, add proxy features | å°æ–¼å¤–åŒ¯æ•¸æ“šï¼Œæˆäº¤é‡å¯èƒ½æ²’æœ‰æ„ç¾©ï¼Œæ·»åŠ ä»£ç†ç‰¹å¾µ
                df['volume_proxy'] = df['hl_range'] * 1000  # Use range as volume proxy | ä½¿ç”¨ç¯„åœä½œç‚ºæˆäº¤é‡ä»£ç†
                return df
            
            # Volume moving averages | æˆäº¤é‡ç§»å‹•å¹³å‡ç·š
            for period in [5, 10, 20]:
                if len(df) >= period:
                    df[f'volume_sma_{period}'] = df['Volume'].rolling(window=period).mean()
                    df[f'volume_ratio_{period}'] = df['Volume'] / df[f'volume_sma_{period}']
            
            # On-Balance Volume | èƒ½é‡æ½®
            df['obv'] = self.technical_indicators.obv(df['Close'], df['Volume'])
            
            # Volume Price Trend | æˆäº¤é‡åƒ¹æ ¼è¶¨å‹¢
            df['vpt'] = ((df['Close'] - df['Close'].shift(1)) / df['Close'].shift(1) * df['Volume']).cumsum()
            
            return df
        except Exception as e:
            self.logger.error(f"âŒ Error adding volume features: {str(e)}")
            return df
    
    def _add_statistical_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Add statistical features | æ·»åŠ çµ±è¨ˆç‰¹å¾µ"""
        try:
            # Rolling statistics | æ»¾å‹•çµ±è¨ˆ
            for period in [10, 20]:
                if len(df) >= period:
                    returns = df['Close'].pct_change()
                    
                    # Skewness and Kurtosis | ååº¦å’Œå³°åº¦
                    df[f'skewness_{period}'] = returns.rolling(window=period).skew()
                    df[f'kurtosis_{period}'] = returns.rolling(window=period).kurt()
                    
                    # Z-score | Zåˆ†æ•¸
                    df[f'zscore_{period}'] = (df['Close'] - df['Close'].rolling(window=period).mean()) / df['Close'].rolling(window=period).std()
            
            # Support and Resistance levels | æ”¯æ’‘å’Œé˜»åŠ›ä½
            df['support_20'] = df['Low'].rolling(window=20).min()
            df['resistance_20'] = df['High'].rolling(window=20).max()
            df['support_distance'] = (df['Close'] - df['support_20']) / df['Close'] * 100
            df['resistance_distance'] = (df['resistance_20'] - df['Close']) / df['Close'] * 100
            
            return df
        except Exception as e:
            self.logger.error(f"âŒ Error adding statistical features: {str(e)}")
            return df
    
    def _clean_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Clean and validate features | æ¸…ç†å’Œé©—è­‰ç‰¹å¾µ"""
        try:
            # Replace infinite values with NaN | å°‡ç„¡é™å€¼æ›¿æ›ç‚ºNaN
            df = df.replace([np.inf, -np.inf], np.nan)
            
            # Forward fill NaN values (limited) | å‰å‘å¡«å……NaNå€¼ï¼ˆæœ‰é™ï¼‰
            df = df.fillna(method='ffill', limit=5)
            
            # Drop rows with too many NaN values | åˆªé™¤NaNå€¼éŽå¤šçš„è¡Œ
            nan_threshold = 0.5  # Allow up to 50% NaN values | å…è¨±æœ€å¤š50%çš„NaNå€¼
            df = df.dropna(thresh=int(len(df.columns) * (1 - nan_threshold)))
            
            # Remove columns with all NaN values | åˆªé™¤å…¨éƒ¨ç‚ºNaNå€¼çš„åˆ—
            df = df.dropna(axis=1, how='all')
            
            self.logger.info(f"ðŸ”„ Feature cleaning complete: {df.shape[0]} rows, {df.shape[1]} features")
            return df
            
        except Exception as e:
            self.logger.error(f"âŒ Error cleaning features: {str(e)}")
            return df
    
    def get_feature_names(self) -> List[str]:
        """Get list of feature names | ç²å–ç‰¹å¾µåç¨±åˆ—è¡¨"""
        return self.feature_names.copy()
    
    def get_feature_importance_data(self, df: pd.DataFrame) -> Dict[str, Any]:
        """Get feature importance data for analysis | ç²å–ç”¨æ–¼åˆ†æžçš„ç‰¹å¾µé‡è¦æ€§æ•¸æ“š"""
        try:
            feature_info = {}
            
            for col in df.columns:
                if col in ['Open', 'High', 'Low', 'Close', 'Volume']:
                    continue  # Skip original OHLCV columns | è·³éŽåŽŸå§‹OHLCVåˆ—
                
                feature_info[col] = {
                    'type': self._classify_feature_type(col),
                    'non_null_count': df[col].count(),
                    'null_percentage': (df[col].isnull().sum() / len(df)) * 100,
                    'mean': df[col].mean() if pd.api.types.is_numeric_dtype(df[col]) else None,
                    'std': df[col].std() if pd.api.types.is_numeric_dtype(df[col]) else None
                }
            
            return feature_info
            
        except Exception as e:
            self.logger.error(f"âŒ Error getting feature importance data: {str(e)}")
            return {}
    
    def _classify_feature_type(self, feature_name: str) -> str:
        """Classify feature type based on name | æ ¹æ“šåç¨±åˆ†é¡žç‰¹å¾µé¡žåž‹"""
        feature_name = feature_name.lower()
        
        if any(term in feature_name for term in ['sma', 'ema', 'ma_']):
            return 'moving_average'
        elif any(term in feature_name for term in ['rsi', 'macd', 'cci', 'williams']):
            return 'momentum'
        elif any(term in feature_name for term in ['bb_', 'bollinger', 'atr', 'volatility']):
            return 'volatility'
        elif any(term in feature_name for term in ['volume', 'obv', 'vpt']):
            return 'volume'
        elif any(term in feature_name for term in ['hour', 'day_', 'month', 'session', 'weekend']):
            return 'time_based'
        elif any(term in feature_name for term in ['price', 'change', 'range', 'body', 'shadow']):
            return 'price_based'
        elif any(term in feature_name for term in ['skewness', 'kurtosis', 'zscore', 'support', 'resistance']):
            return 'statistical'
        else:
            return 'other'


# For backward compatibility | ç‚ºäº†å‘å¾Œå…¼å®¹
def create_feature_generator(lookback_periods: List[int] = None) -> FeatureGenerator:
    """Create a FeatureGenerator instance | å‰µå»ºFeatureGeneratorå¯¦ä¾‹"""
    return FeatureGenerator(lookback_periods)