"""
AIFX Phase 1-2 Integration Test Suite | AIFXç¬¬ä¸€éšæ®µ-ç¬¬äºŒéšæ®µæ•´åˆæ¸¬è©¦å¥—ä»¶

Focused testing for integration and conflict resolution between Phase 1 and Phase 2.
å°ˆæ³¨æ–¼ç¬¬ä¸€éšæ®µå’Œç¬¬äºŒéšæ®µé–“æ•´åˆå’Œè¡çªè§£æ±ºçš„æ¸¬è©¦ã€‚

Usage | ä½¿ç”¨æ–¹æ³•:
    python test_integration_phase1_phase2.py
"""

import sys
import os
import traceback
import warnings
from datetime import datetime
import numpy as np
import pandas as pd
import importlib

warnings.filterwarnings('ignore')

# Add src path for imports | ç‚ºå°å…¥æ·»åŠ srcè·¯å¾‘
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src', 'main', 'python'))

class Colors:
    """Console colors for output formatting | è¼¸å‡ºæ ¼å¼çš„æ§åˆ¶å°é¡è‰²"""
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    WHITE = '\033[97m'
    BOLD = '\033[1m'
    END = '\033[0m'

class IntegrationTester:
    """Integration testing between Phase 1 and Phase 2 | ç¬¬ä¸€éšæ®µå’Œç¬¬äºŒéšæ®µé–“çš„æ•´åˆæ¸¬è©¦"""
    
    def __init__(self):
        self.test_results = []
        self.total_tests = 0
        self.passed_tests = 0
        self.failed_tests = 0
        self.warnings = []
        self.start_time = datetime.now()
        
        print(f"{Colors.BOLD}{Colors.BLUE}ğŸ”„ AIFX Phase 1-2 Integration Test Suite{Colors.END}")
        print(f"{Colors.CYAN}Testing integration and conflict resolution... | æ­£åœ¨æ¸¬è©¦æ•´åˆå’Œè¡çªè§£æ±º...{Colors.END}\n")
    
    def log_test(self, test_name: str, passed: bool, message: str = "", warning: str = ""):
        """Log test result | è¨˜éŒ„æ¸¬è©¦çµæœ"""
        self.total_tests += 1
        
        if passed:
            self.passed_tests += 1
            status = f"{Colors.GREEN}âœ… PASS{Colors.END}"
        else:
            self.failed_tests += 1
            status = f"{Colors.RED}âŒ FAIL{Colors.END}"
        
        print(f"{status} {test_name}")
        if message:
            print(f"    {Colors.WHITE}{message}{Colors.END}")
        if warning:
            print(f"    {Colors.YELLOW}âš ï¸ {warning}{Colors.END}")
            self.warnings.append(warning)
    
    def test_import_compatibility(self):
        """Test that all imports work without conflicts | æ¸¬è©¦æ‰€æœ‰å°å…¥éƒ½èƒ½æ­£å¸¸å·¥ä½œï¼Œç„¡è¡çª"""
        print(f"{Colors.BOLD}1. Import Compatibility Tests | å°å…¥å…¼å®¹æ€§æ¸¬è©¦{Colors.END}")
        
        # Test Phase 1 imports | æ¸¬è©¦ç¬¬ä¸€éšæ®µå°å…¥
        phase1_modules = [
            ('utils.config', 'Configuration system'),
            ('utils.logger', 'Logging system'),
            ('utils.data_loader', 'Data loading utilities'),
            ('utils.data_preprocessor', 'Data preprocessing'),
            ('utils.technical_indicators', 'Technical indicators')
        ]
        
        for module_name, description in phase1_modules:
            try:
                importlib.import_module(module_name)
                self.log_test(f"Phase 1 Import: {module_name}", True, description)
            except Exception as e:
                self.log_test(f"Phase 1 Import: {module_name}", False, f"Error: {str(e)}")
        
        # Test Phase 2 imports (without TensorFlow dependencies) | æ¸¬è©¦ç¬¬äºŒéšæ®µå°å…¥ï¼ˆä¸å«TensorFlowä¾è³´ï¼‰
        phase2_modules = [
            ('models.xgboost_model', 'XGBoost model implementation'),
            ('models.random_forest_model', 'Random Forest model implementation')
        ]
        
        for module_name, description in phase2_modules:
            try:
                importlib.import_module(module_name)
                self.log_test(f"Phase 2 Import: {module_name}", True, description)
            except Exception as e:
                self.log_test(f"Phase 2 Import: {module_name}", False, f"Error: {str(e)}")
        
        # Test problematic imports separately | å–®ç¨æ¸¬è©¦æœ‰å•é¡Œçš„å°å…¥
        try:
            from models import lstm_model
            self.log_test("Phase 2 LSTM Import", False, "Should fail gracefully without TensorFlow")
        except ImportError as e:
            if "tensorflow" in str(e).lower() or "tf" in str(e).lower():
                self.log_test("Phase 2 LSTM Import", True, "Failed gracefully - TensorFlow not available", 
                             "TensorFlow required for LSTM functionality")
            else:
                self.log_test("Phase 2 LSTM Import", False, f"Unexpected import error: {str(e)}")
        except Exception as e:
            self.log_test("Phase 2 LSTM Import", False, f"Unexpected error: {str(e)}")
    
    def test_data_flow_compatibility(self):
        """Test data flow from Phase 1 to Phase 2 | æ¸¬è©¦å¾ç¬¬ä¸€éšæ®µåˆ°ç¬¬äºŒéšæ®µçš„æ•¸æ“šæµ"""
        print(f"\n{Colors.BOLD}2. Data Flow Compatibility | æ•¸æ“šæµå…¼å®¹æ€§{Colors.END}")
        
        try:
            # Initialize Phase 1 components | åˆå§‹åŒ–ç¬¬ä¸€éšæ®µçµ„ä»¶
            from utils.data_loader import DataLoader
            from utils.data_preprocessor import DataPreprocessor
            from utils.technical_indicators import TechnicalIndicators
            
            data_loader = DataLoader()
            preprocessor = DataPreprocessor()
            indicators = TechnicalIndicators()
            
            self.log_test("Phase 1 Component Initialization", True, "All components initialized")
            
            # Create sample forex data | å‰µå»ºæ¨£æœ¬å¤–åŒ¯æ•¸æ“š
            dates = pd.date_range('2024-01-01', periods=200, freq='H')
            np.random.seed(42)  # For reproducible results | ç‚ºå¯é‡ç¾çµæœ
            
            prices = 1.1000 + np.cumsum(np.random.normal(0, 0.001, 200))
            sample_data = pd.DataFrame({
                'Open': prices + np.random.normal(0, 0.0001, 200),
                'High': prices + abs(np.random.normal(0, 0.0003, 200)),
                'Low': prices - abs(np.random.normal(0, 0.0003, 200)),
                'Close': prices,
                'Volume': np.random.uniform(1000, 5000, 200)
            }, index=dates)
            
            # Fix OHLC relationships | ä¿®å¾©OHLCé—œä¿‚
            for i in range(len(sample_data)):
                max_oc = max(sample_data.iloc[i]['Open'], sample_data.iloc[i]['Close'])
                min_oc = min(sample_data.iloc[i]['Open'], sample_data.iloc[i]['Close'])
                sample_data.iloc[i]['High'] = max(sample_data.iloc[i]['High'], max_oc)
                sample_data.iloc[i]['Low'] = min(sample_data.iloc[i]['Low'], min_oc)
            
            self.log_test("Sample Data Creation", True, f"Created {len(sample_data)} OHLCV records")
            
            # Step 1: Add technical indicators | æ­¥é©Ÿ1ï¼šæ·»åŠ æŠ€è¡“æŒ‡æ¨™
            data_with_indicators = indicators.add_all_indicators(sample_data)
            original_cols = len(sample_data.columns)
            new_cols = len(data_with_indicators.columns)
            
            if new_cols > original_cols:
                self.log_test("Technical Indicators Integration", True, 
                             f"Added {new_cols - original_cols} technical indicators")
            else:
                self.log_test("Technical Indicators Integration", False, "No indicators added")
            
            # Step 2: Preprocess data | æ­¥é©Ÿ2ï¼šé è™•ç†æ•¸æ“š
            processed_data = preprocessor.preprocess_data(data_with_indicators, 
                                                        normalize=False,
                                                        remove_outliers=False)
            
            if len(processed_data) >= len(sample_data) * 0.7:  # At least 70% retained | è‡³å°‘ä¿ç•™70%
                self.log_test("Data Preprocessing", True, 
                             f"Processed {len(processed_data)} records, {processed_data.shape[1]} features")
            else:
                self.log_test("Data Preprocessing", False, 
                             f"Too much data lost: {len(processed_data)}/{len(sample_data)}")
            
            # Step 3: Extract features and targets | æ­¥é©Ÿ3ï¼šæå–ç‰¹å¾µå’Œç›®æ¨™
            X, y = preprocessor.get_features_and_target(processed_data)
            
            if len(X) > 0 and len(y) > 0 and len(X) == len(y):
                self.log_test("Feature-Target Extraction", True, 
                             f"Features: {X.shape}, Target: {len(y)}")
            else:
                self.log_test("Feature-Target Extraction", False, 
                             f"Feature-target mismatch: X={X.shape if hasattr(X, 'shape') else 'None'}, y={len(y)}")
                return False
            
            # Step 4: Test with Phase 2 models | æ­¥é©Ÿ4ï¼šä½¿ç”¨ç¬¬äºŒéšæ®µæ¨¡å‹æ¸¬è©¦
            from models.xgboost_model import XGBoostModel
            from models.random_forest_model import RandomForestModel
            
            # Test XGBoost integration | æ¸¬è©¦XGBoostæ•´åˆ
            xgb_model = XGBoostModel()
            
            # Use subset for quick training | ä½¿ç”¨å­é›†é€²è¡Œå¿«é€Ÿè¨“ç·´
            subset_size = min(100, len(X))
            X_subset = X[:subset_size]
            y_subset = y[:subset_size]
            
            training_history = xgb_model.train(X_subset, y_subset, optimize_hyperparameters=False)
            
            if training_history and xgb_model.is_trained:
                # Test prediction | æ¸¬è©¦é æ¸¬
                test_predictions = xgb_model.predict(X_subset[-20:])
                if len(test_predictions) == 20:
                    self.log_test("XGBoost Full Integration", True, "Training and prediction successful")
                else:
                    self.log_test("XGBoost Full Integration", False, "Prediction failed")
            else:
                self.log_test("XGBoost Full Integration", False, "Training failed")
            
            # Test Random Forest integration | æ¸¬è©¦éš¨æ©Ÿæ£®æ—æ•´åˆ
            rf_model = RandomForestModel()
            training_history = rf_model.train(X_subset, y_subset, optimize_hyperparameters=False)
            
            if training_history and rf_model.is_trained:
                test_predictions = rf_model.predict(X_subset[-20:])
                if len(test_predictions) == 20:
                    self.log_test("Random Forest Full Integration", True, "Training and prediction successful")
                else:
                    self.log_test("Random Forest Full Integration", False, "Prediction failed")
            else:
                self.log_test("Random Forest Full Integration", False, "Training failed")
            
            return True
            
        except Exception as e:
            self.log_test("Data Flow Compatibility", False, f"Error: {str(e)}")
            traceback.print_exc()
            return False
    
    def test_memory_and_performance(self):
        """Test memory usage and performance | æ¸¬è©¦è¨˜æ†¶é«”ä½¿ç”¨å’Œæ€§èƒ½"""
        print(f"\n{Colors.BOLD}3. Memory and Performance Tests | è¨˜æ†¶é«”å’Œæ€§èƒ½æ¸¬è©¦{Colors.END}")
        
        try:
            import psutil
            import gc
            
            # Get initial memory usage | ç²å–åˆå§‹è¨˜æ†¶é«”ä½¿ç”¨
            process = psutil.Process()
            initial_memory = process.memory_info().rss / 1024 / 1024  # MB
            
            # Run data processing pipeline | é‹è¡Œæ•¸æ“šè™•ç†ç®¡é“
            from utils.data_loader import DataLoader
            from utils.data_preprocessor import DataPreprocessor
            from utils.technical_indicators import TechnicalIndicators
            from models.xgboost_model import XGBoostModel
            
            # Create larger dataset for memory test | ç‚ºè¨˜æ†¶é«”æ¸¬è©¦å‰µå»ºæ›´å¤§æ•¸æ“šé›†
            dates = pd.date_range('2024-01-01', periods=1000, freq='H')
            np.random.seed(42)
            
            prices = 1.1000 + np.cumsum(np.random.normal(0, 0.001, 1000))
            large_dataset = pd.DataFrame({
                'Open': prices + np.random.normal(0, 0.0001, 1000),
                'High': prices + abs(np.random.normal(0, 0.0003, 1000)),
                'Low': prices - abs(np.random.normal(0, 0.0003, 1000)),
                'Close': prices,
                'Volume': np.random.uniform(1000, 5000, 1000)
            }, index=dates)
            
            # Process through full pipeline | é€šéå®Œæ•´ç®¡é“è™•ç†
            indicators = TechnicalIndicators()
            preprocessor = DataPreprocessor()
            
            data_with_indicators = indicators.add_all_indicators(large_dataset)
            processed_data = preprocessor.preprocess_data(data_with_indicators, 
                                                        normalize=False,
                                                        remove_outliers=False)
            X, y = preprocessor.get_features_and_target(processed_data)
            
            # Train model | è¨“ç·´æ¨¡å‹
            model = XGBoostModel()
            subset_size = min(200, len(X))
            model.train(X[:subset_size], y[:subset_size], optimize_hyperparameters=False)
            
            # Get final memory usage | ç²å–æœ€çµ‚è¨˜æ†¶é«”ä½¿ç”¨
            final_memory = process.memory_info().rss / 1024 / 1024  # MB
            memory_increase = final_memory - initial_memory
            
            # Memory usage check | è¨˜æ†¶é«”ä½¿ç”¨æª¢æŸ¥
            if memory_increase < 500:  # Less than 500MB increase | å¢åŠ ä¸åˆ°500MB
                self.log_test("Memory Usage", True, f"Memory increase: {memory_increase:.1f} MB")
            else:
                self.log_test("Memory Usage", False, f"High memory usage: {memory_increase:.1f} MB",
                             "Consider memory optimization")
            
            # Garbage collection test | åƒåœ¾å›æ”¶æ¸¬è©¦
            del data_with_indicators, processed_data, model
            gc.collect()
            
            after_gc_memory = process.memory_info().rss / 1024 / 1024  # MB
            memory_freed = final_memory - after_gc_memory
            
            if memory_freed > 0:
                self.log_test("Memory Cleanup", True, f"Freed {memory_freed:.1f} MB after cleanup")
            else:
                self.log_test("Memory Cleanup", True, "Memory cleanup completed", 
                             "No significant memory freed - normal behavior")
            
        except ImportError:
            self.log_test("Memory and Performance Tests", True, "", "psutil not available - memory tests skipped")
        except Exception as e:
            self.log_test("Memory and Performance Tests", False, f"Error: {str(e)}")
    
    def test_dependency_conflicts(self):
        """Test for dependency version conflicts | æ¸¬è©¦ä¾è³´ç‰ˆæœ¬è¡çª"""
        print(f"\n{Colors.BOLD}4. Dependency Conflict Tests | ä¾è³´è¡çªæ¸¬è©¦{Colors.END}")
        
        try:
            # Test critical dependencies | æ¸¬è©¦é—œéµä¾è³´
            critical_deps = [
                'pandas', 'numpy', 'sklearn', 'xgboost', 'matplotlib'
            ]
            
            for dep in critical_deps:
                try:
                    module = importlib.import_module(dep)
                    version = getattr(module, '__version__', 'unknown')
                    self.log_test(f"Dependency: {dep}", True, f"Version: {version}")
                except ImportError:
                    self.log_test(f"Dependency: {dep}", False, "Not installed")
            
            # Test for common conflicts | æ¸¬è©¦å¸¸è¦‹è¡çª
            try:
                import sklearn
                import xgboost
                
                # Try to use both together | å˜—è©¦ä¸€èµ·ä½¿ç”¨
                from sklearn.model_selection import train_test_split
                import xgboost as xgb
                
                # Create sample data | å‰µå»ºæ¨£æœ¬æ•¸æ“š
                X = np.random.random((100, 5))
                y = np.random.randint(0, 2, 100)
                
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
                
                # Test XGBoost with sklearn compatibility | æ¸¬è©¦XGBoostèˆ‡sklearnå…¼å®¹æ€§
                xgb_classifier = xgb.XGBClassifier(n_estimators=10, random_state=42, verbosity=0)
                xgb_classifier.fit(X_train, y_train)
                predictions = xgb_classifier.predict(X_test)
                
                if len(predictions) == len(X_test):
                    self.log_test("SKLearn-XGBoost Compatibility", True, "No conflicts detected")
                else:
                    self.log_test("SKLearn-XGBoost Compatibility", False, "Prediction mismatch")
                
            except Exception as e:
                self.log_test("SKLearn-XGBoost Compatibility", False, f"Conflict detected: {str(e)}")
            
        except Exception as e:
            self.log_test("Dependency Conflict Tests", False, f"Error: {str(e)}")
    
    def generate_report(self):
        """Generate final integration test report | ç”Ÿæˆæœ€çµ‚æ•´åˆæ¸¬è©¦å ±å‘Š"""
        end_time = datetime.now()
        duration = (end_time - self.start_time).total_seconds()
        
        print(f"\n{Colors.BOLD}{Colors.BLUE}ğŸ”„ AIFX Phase 1-2 Integration Test Report{Colors.END}")
        print("="*70)
        
        pass_rate = (self.passed_tests / self.total_tests * 100) if self.total_tests > 0 else 0
        
        print(f"{Colors.BOLD}Integration Test Summary | æ•´åˆæ¸¬è©¦æ‘˜è¦:{Colors.END}")
        print(f"  Total Tests: {self.total_tests}")
        print(f"  Passed: {Colors.GREEN}{self.passed_tests}{Colors.END}")
        print(f"  Failed: {Colors.RED}{self.failed_tests}{Colors.END}")
        print(f"  Pass Rate: {Colors.GREEN if pass_rate >= 80 else Colors.YELLOW}{pass_rate:.1f}%{Colors.END}")
        print(f"  Duration: {duration:.2f}s")
        
        if self.warnings:
            print(f"\n{Colors.YELLOW}âš ï¸ Warnings ({len(self.warnings)}):{Colors.END}")
            for warning in self.warnings:
                print(f"  â€¢ {warning}")
        
        # Overall assessment | ç¸½é«”è©•ä¼°
        print(f"\n{Colors.BOLD}Integration Assessment | æ•´åˆè©•ä¼°:{Colors.END}")
        
        if pass_rate >= 85:
            status = f"{Colors.GREEN}âœ… EXCELLENT{Colors.END}"
            message = "Phase 1 and Phase 2 integrate perfectly | ç¬¬ä¸€éšæ®µå’Œç¬¬äºŒéšæ®µå®Œç¾æ•´åˆ"
            readiness = f"{Colors.GREEN}âœ… READY for Phase 3 Development{Colors.END}"
        elif pass_rate >= 70:
            status = f"{Colors.GREEN}âœ… GOOD{Colors.END}"
            message = "Phase 1 and Phase 2 integrate well with minor issues | ç¬¬ä¸€éšæ®µå’Œç¬¬äºŒéšæ®µæ•´åˆè‰¯å¥½ï¼Œæœ‰è¼•å¾®å•é¡Œ"
            readiness = f"{Colors.GREEN}âœ… READY for Phase 3 Development{Colors.END}"
        elif pass_rate >= 50:
            status = f"{Colors.YELLOW}âš ï¸ ACCEPTABLE{Colors.END}"
            message = "Phase 1 and Phase 2 have integration issues | ç¬¬ä¸€éšæ®µå’Œç¬¬äºŒéšæ®µæœ‰æ•´åˆå•é¡Œ"
            readiness = f"{Colors.YELLOW}âš ï¸ PROCEED WITH CAUTION to Phase 3{Colors.END}"
        else:
            status = f"{Colors.RED}âŒ POOR{Colors.END}"
            message = "Significant integration conflicts detected | æª¢æ¸¬åˆ°é‡å¤§æ•´åˆè¡çª"
            readiness = f"{Colors.RED}âŒ FIX ISSUES before Phase 3{Colors.END}"
        
        print(f"  Status: {status}")
        print(f"  {message}")
        print(f"\n{Colors.BOLD}Phase 3 Readiness | ç¬¬ä¸‰éšæ®µæº–å‚™ç‹€æ…‹:{Colors.END}")
        print(f"  {readiness}")
        
        # Recommendations | å»ºè­°
        print(f"\n{Colors.BOLD}Recommendations | å»ºè­°:{Colors.END}")
        if self.failed_tests == 0:
            print(f"  â€¢ {Colors.GREEN}All systems integrated successfully{Colors.END}")
            print(f"  â€¢ {Colors.GREEN}Ready to proceed with Phase 3 Strategy Integration{Colors.END}")
        else:
            if any("tensorflow" in w.lower() or "keras" in w.lower() for w in self.warnings):
                print(f"  â€¢ Install TensorFlow for full LSTM functionality: pip install tensorflow")
            if self.failed_tests > 2:
                print(f"  â€¢ Review and fix {self.failed_tests} integration issues before Phase 3")
            print(f"  â€¢ Consider addressing warnings for optimal performance")
        
        return pass_rate >= 70

def main():
    """Main test execution | ä¸»è¦æ¸¬è©¦åŸ·è¡Œ"""
    tester = IntegrationTester()
    
    try:
        tester.test_import_compatibility()
        tester.test_data_flow_compatibility()
        tester.test_memory_and_performance()
        tester.test_dependency_conflicts()
        
        success = tester.generate_report()
        sys.exit(0 if success else 1)
        
    except Exception as e:
        print(f"\n{Colors.RED}Fatal integration error: {str(e)}{Colors.END}")
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()